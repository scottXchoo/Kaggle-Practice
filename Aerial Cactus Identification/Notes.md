## 사용한 것들
### 베이스라인
- 손실 함수 : 교차 엔트로피
- 옵티마이저 : SGD
### 최종 모델
- 손실 함수 :
- 옵티마이저 :

### 딥러닝 모델 훈련 절차
1. 데이터 로더에서 배치 크기만큼 데이터를 불러옵니다.
2. 불러온 이미지 데이터와 레이블(타깃값) 데이터를 장비(GPU 혹은 CPU)에 할당합니다.
3. 옵티마이저 내 기울기를 초기화합니다.
4. 신경망 모델에 입력 데이터(이미지)를 전달해 순전파하여 출력값(예측값)을 구합니다.
5. 예측값과 실제 레이블(타깃값)을 비교해 손실을 계산합니다.
6. 손실을 기반으로 역전파를 수행합니다.
7. 역전파로 구한 기울기를 활용해 가중치를 갱신합니다.
8. 1~7 절차를 반복 횟수(iteration)만큼 되풀이합니다.
9. 1~8 절차를 에폭(epoch)만큼 반복합니다.

### 에폭(epoch) vs. 배치 크기(batch size) vs. 반복 횟수(iteration)
- 에폭 : '훈련 데이터 전체'를 '한 번' 훑었음을 뜻합니다(문제집 한 권을 다 풀었다고 생각하세요). 그런데 신경망 가중치가 최적화되기에는 1에폭만 훈련해서는 부족합니다. 보통 수십~수백 에폭만큼 훈련합니다. 에폭이 너무 적으면 과소적합(underfitting), 너무 많으면 과대적합(overfitting)이 발생합니다.
- 배치 크기 : 매 훈련 반복 횟수에서 한 번에 훈련할 데이터 개수입니다.
- 반복 횟수 : 1에폭의 훈련을 완료하는 데 필요한 훈련 이터레이션을 일컫습니다. `반복 횟수 = 훈련 데이터 개수 / 배치 크기` (소수점은 올림 처리)

### 모델 평가 단계
- 모델 평가 단계에서는 model.eval()과 torch.no_grad() 메서드를 실행합니다.
  - backward() 메서드로 역전파를 한 적이 없다면, torch.no_grad()를 적용하지 않아도 결과에 영향을 주지 않습니다.
  - torch.no_grad()로 필요 없는 계산을 피해 메모리를 아끼고 속도를 높일 수 있습니다.
- 드롭아웃이나 배치 정규화는 훈련 단계에서만 적용해야 합니다.

### 딥러닝 모델링 절차 by 파이토치
1. 시드값 고정 및 GPU 장비 설정
   - 시드값 고정 : 결과 재현을 위한 작업
   - GPU 장비 설정 : 훈련 속도를 높이기 위해 데이터를 GPU가 처리하도록 변경

2. 데이터 준비
   - 훈련/검증 데이터 분리
   - 데이터셋 클래스 정의 : 이미지 데이터를 모델링에 적합한 형태로 불러오도록 해줌
   - 데이터셋 생성
   - 데이터 로더 (데이터셋으로부터 데이터를 배치 단위로 불러와주는 객체) 생성

3. 모델 생성 : 신경망 모델 클래스를 직접 설계한 후 인스턴스 생성

4. 모델 훈련
   - 손실 함수와 옵티마이저 설정 : 훈련에 앞서 손실 함수(예측값과 실젯값의 차이를 구하는 함수)와 옵티마이저(최적 가중치를 찾아주는 알고리즘) 설정
   - 모델 훈련 : 신경망의 가중치(파라미터)를 갱신하며 모델 훈련

5. 성능 검증 : 검증 데이터로 모델 성능 검증

6. 예측 및 제출 : 테스트 데이터로 예측 후 결과 제출

### 파이토치용 컴퓨터 비전 라이브러리인 torchvision의 transform 모듈이 제공하는 주요 변환기들
- Compose() : 여러 변환기를 묶어줌
- ToTensor() : PIL(Python Imaging Library) 이미지나 ndarray를 텐서로 변환
- Pad() : 이미지 주변에 패딩 추가
- RandomHorizontalFlip() : 이미지를 무작위로 좌우 대칭 변환
- RandomVerticalFlip() : 이미지를 무작위로 상하 대칭 변환
- Normalize() : 텐서 형태의 이미지 데이터를 정규화

### 데이터 증강
- 변환기 중 RandomHorizontalFlip(), RandomVerticalFlip(), RandomRotation()은 변환을 무작위로 가하기 때문에 매번 다르게 변환합니다. 즉, 원본 이미지는 같지만 첫 번째 에폭과 두 번째 에폭에서 서로 다른 이미지로 훈련하는 효과를 얻을 수 있는 거죠.

### 이미지 데이터 압축 푸는 방법
```python
from zipfile import ZipFile

# 훈련 이미지 데이터 압축 풀기
with ZipFile(data_path + 'train.zip') as zipper:
    zipper.extractall()
    
# 테스트 이미지 데이터 압축 풀기
with ZipFile(data_path + 'test.zip') as zipper:
    zipper.extractall()
```

### 이미지 출력하는 방법
```python
import matplotlib.gridspec as gridspec
import cv2 # OpenCV 라이브러리 임포트

mpl.rc('font', size = 7)
plt.figure(figsize = (15, 6))  # 전체 Figure 크기 설정
grid = gridspec.GridSpec(2, 6) # 서브플롯 배치 (2행 6열로 출력)

# 1. 선인장을 포함하는 이미지 파일명 (마지막 12개)
last_has_cactus_img_name = labels[labels['has_cactus'] == 1]['id'][-12:]

# 2. 이미지 출력
for idx, img_name in enumerate(last_has_cactus_img_name):
    img_path = 'train/' + img_name                 # 3. 이미지 파일 경로
    image = cv2.imread(img_path)                   # 4. 이미지 파일 읽기
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 5. 이미지 색상 보정
    ax = plt.subplot(grid[idx])
    ax.imshow(image)                               # 6. 이미지 출력
```
5번 : cv2.imread()로 이미지를 읽으면 색상 채널을 BGR(파랑, 초록, 빨강) 순서로 불러옵니다. 하지만 RGB 순서이어야 실제 색상과 맞으므로 채널 순서를 바꿔줘야 합니다.

### Tips
- 파이토치로 신경망 모델을 구축하려면 데이터셋도 일정한 형식에 맞게 정의해줘야 합니다.
- 파이토치로 이미지를 처리할 때는 형상이 (채널 수, 가로 픽셀 수, 세로 픽셀 수) 순서여야 합니다.
- 배치 크기는 2의 제곱수로 설정하는 게 효율적입니다.
  - 배치 크기가 작으면 규제 효과가 있어 일반화 성능이 좋아집니다.
  - 단, 한 번에 불러오는 데이터가 적어 훈련 이터레이션이 많아지고 훈련 시간도 길어집니다.
  - 게다가 배치 크기가 작을수록 학습률도 작게 설정해야 하는데, 훈련 시간을 지연시키는 또 다른 원인입니다.
- 신경망 계층이 깊어지면 대체로 예측력이 좋아집니다. 다만 지나치게 깊으면 과대적합될 우려가 있으니 유의하세요.
- 배치 크기가 줄어들수록 그만큼 학습률도 작게 설정해야 합니다. 반대로 배치 크기가 클수록 학습률도 크게 설정하는 게 바람직합니다.
- 데이터 증강 없이 단순히 에폭만 늘리면 과적합되기 쉬워진다. (?)
