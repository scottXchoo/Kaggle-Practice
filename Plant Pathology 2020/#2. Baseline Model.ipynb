{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Baseline Model\n\n베이스 라인을 만들 차례입니다. 아래는 베이스 라인 모델을 만드는 과정입니다.\n\n1. Fix the seed value and set up your GPU equipment (시드값 고정 및 GPU 장비 설정)\n   - [1] Fix the seed value (시드값 고정)\n   - [2] Set up GPU equipment (GPU 장비 설정)\n2. Prepare Data (데이터 준비)\n   - [1] Separate training/validation data (훈련/검증 데이터 분리)\n   - [2] Define dataset classes (데이터셋 클래스 정의)\n   - [3] Define image transformer (이미지 변환기 정의)\n   - [4] Create datasets & a data loader (데이터셋 및 데이터 로더 생성)\n3. Create Model (모델 생성)\n   - [1] Pre-trained models and transfer learing (사전 훈련 모델과 전이 학습)\n   - [2] Create an EfficientNet model (EfficientNet 모델 생성)\n4. Train Model & Validate Performance (모델 훈련 및 성능 검증)\n   - [1] Set Loss Function & Optimizer (손실 함수와 옵티마이저 설정)\n   - [2] Train & Validate Performance (훈련 및 성능 검증)\n5. Predict & Submission (예측 및 제출)\n   - [1] Predict (예측)\n   - [2] Submission (제출)","metadata":{}},{"cell_type":"markdown","source":"## 1. Fix the seed value and set up your GPU equipment (시드값 고정 및 GPU 장비 설정)\n\n### [1] Fix the seed value (시드값 고정)\n\n먼저 시드값을 고정합니다.","metadata":{}},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport os\n\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:40.349747Z","iopub.execute_input":"2023-10-03T10:20:40.350260Z","iopub.status.idle":"2023-10-03T10:20:44.276116Z","shell.execute_reply.started":"2023-10-03T10:20:40.350225Z","shell.execute_reply":"2023-10-03T10:20:44.275122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### [2] Set up GPU equipment (GPU 장비 설정)\n\n다음으로 장비를 할당할 차례입니다. 오른쪽 [Settings] 탭에서 Accelerator를 \"GPU T4 x2\"로 바꾸고, 이어서 다음 코드를 실행합니다.","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:44.278110Z","iopub.execute_input":"2023-10-03T10:20:44.278852Z","iopub.status.idle":"2023-10-03T10:20:44.311415Z","shell.execute_reply.started":"2023-10-03T10:20:44.278820Z","shell.execute_reply":"2023-10-03T10:20:44.310399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Prepare Data (데이터 준비)\n\n데이터를 먼저 불러옵니다.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:44.313983Z","iopub.execute_input":"2023-10-03T10:20:44.315065Z","iopub.status.idle":"2023-10-03T10:20:44.856917Z","shell.execute_reply.started":"2023-10-03T10:20:44.314965Z","shell.execute_reply":"2023-10-03T10:20:44.855888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### [1] Separate training/validation data (훈련/검증 데이터 분리)\n\n전체 훈련 데이터인 train을 훈련 데이터와 검증 데이터로 분리하겠습니다.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, valid = train_test_split(train,\n                               test_size = 0.1,\n                               stratify = train[['healthy', 'multiple_diseases', 'rust', 'scab']],\n                               random_state = 50)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:44.863559Z","iopub.execute_input":"2023-10-03T10:20:44.866094Z","iopub.status.idle":"2023-10-03T10:20:45.569042Z","shell.execute_reply.started":"2023-10-03T10:20:44.866060Z","shell.execute_reply":"2023-10-03T10:20:45.568125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"타깃값이 고루 분포되도록 분리하기 위해 stratify 파라미터에 타깃값 4개를 전달했습니다.","metadata":{}},{"cell_type":"markdown","source":"### [2] Define dataset classes (데이터셋 클래스 정의)\n\n데이터셋 클래스를 정의합니다.","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset\nimport numpy as np\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir = './', transform = None, is_test = False):\n        super().__init__() # 상속받은 Dataset의 __init__() 메서드 호출\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        # (1)\n        self.is_test = is_test\n    \n    # 데이터셋 크기 반환 메서드\n    def __len__(self):\n        return len(self.df)\n    \n    # 인덱스(idx)에 해당하는 데이터 반환 메서드\n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]\n        img_path = self.img_dir + img_id + '.jpg' # (2) 이미지 파일 경로\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        # 이미지 변환\n        if self.transform is not None:\n            image = self.transform(image = image)['image']\n        # 테스트 데이터면 이미지 데이터만 반환, 그렇지 않으면 타깃값도 반환\n        if self.is_test: # (4)\n            return image # (5) 테스트용일 때\n        else:\n            # (6) 타깃값 4개 중 가장 큰 값의 인덱스\n            label = np.argmax(self.df.iloc[idx, 1:5])\n            return image, label # (7) 훈련/검증용일 때","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:45.573317Z","iopub.execute_input":"2023-10-03T10:20:45.575403Z","iopub.status.idle":"2023-10-03T10:20:45.785740Z","shell.execute_reply.started":"2023-10-03T10:20:45.575370Z","shell.execute_reply":"2023-10-03T10:20:45.784835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"(1) 데이터셋을 테스트용으로 만들려면 초기화 메서드의 is_test 파라미터에 True를, 훈련이나 검증용으로 만들려면 False를 전달합니다.\n\n__getitem__() 메서드로 데이터를 가져올 때는 생성 시 지정한 (4) is_test 값을 확인해서, (5) 테스트 데이터용이라면 테스트 데이터에는 타깃값이 없기 때문에 이미지 데이터만 반환하고 (7) 훈련 혹은 검증용이라면 타깃값도 함께 반환합니다.\n\n(6) 훈련 혹은 검증용일 경우 타깃값은 4가지(self.df.iloc[idx, 1:5]) 중 가장 큰 값의 인덱스(np.argmax(...))가 됩니다. 즉, 가장 큰 타깃값이 healthy면 0, multiple_disease면 1, rust면 2, scab이면 3을 label에 할당합니다.\n\n(2)에서는 이미지 파일 경로 끝에 파일 확장자(.jpg)를 덧붙였습니다.","metadata":{}},{"cell_type":"markdown","source":"### [3] Define image transformer (이미지 변환기 정의)\n\n데이터 증강용 이미지 변환기를 정의할 차례입니다. 이번에는 albumentations가 제공하는 이미지 변환기를 사용할 겁니다. torchvision의 변환기와 비교했을 때, 처리 속도가 빠르고, 더 다양한 이미지 변환을 제공한다는 장점이 있습니다.","metadata":{}},{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:45.787261Z","iopub.execute_input":"2023-10-03T10:20:45.787890Z","iopub.status.idle":"2023-10-03T10:20:47.108689Z","shell.execute_reply.started":"2023-10-03T10:20:45.787858Z","shell.execute_reply":"2023-10-03T10:20:47.107790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'훈련 데이터용' 변환기부터 정의한 후, 바로 이어서 '검증 및 테스트 데이터용'을 정의하겠습니다.","metadata":{}},{"cell_type":"code","source":"transform_train = A.Compose([\n    A.Resize(450, 650), # (1) 이미지 크기 조절\n    A.RandomBrightnessContrast(brightness_limit = 0.2, # (2) 밝기 대비 조절\n                               contrast_limit = 0.2, p = 0.3),\n    A.VerticalFlip(p = 0.2),   # 상하 대칭 변환\n    A.HorizontalFlip(p = 0.5), # 좌우 대칭 변환\n    A.ShiftScaleRotate(        # (3) 이동, 스케일링, 회전 변환\n        shift_limit = 0.1,\n        scale_limit = 0.2,\n        rotate_limit = 30, p = 0.3),\n    A.OneOf([A.Emboss(p = 1), # (4) 양각화, 날카로움, 블러 효과\n             A.Sharpen(p = 1),\n             A.Blur(p = 1)], p = 0.3),\n    A.PiecewiseAffine(p = 0.3), # (5) 어파인 변환\n    A.Normalize(), # (6) 정규화 변환\n    ToTensorV2()   # (7) 텐서로 변환\n])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:47.109981Z","iopub.execute_input":"2023-10-03T10:20:47.110858Z","iopub.status.idle":"2023-10-03T10:20:47.118401Z","shell.execute_reply.started":"2023-10-03T10:20:47.110824Z","shell.execute_reply":"2023-10-03T10:20:47.117438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"(1) Resize : 이미지 크기를 조절하는 변환기\n\n(2) RandomBrightnessContrast : 이미지의 밝기와 대비를 조절하는 변환기\n\n(3) ShiftScaleRotate : 이동, 스케일링, 회전 변환기\n\n(4) 양각화 효과(Emboss), 날카롭게 만드는 효과(Sharpen), 블러 효과(Blur) 중 하나를 선택(OneOf)해 적용합니다.\n\n(5) PiecewiseAffine : 어파인 변환기입니다. 어파인 변환이란 이동, 확대/축소, 회전 등으로 이미지 모양을 전체적으로 바꾸는 변환입니다.\n\n(6) Normalize : 값을 정규화하는 변환기로, torchvision의 transform.Normalize()와 비슷합니다.\n\n(7) ToTesnorV2() : 이미지 데이터를 텐서 형식으로 변환합니다. torchvision의 transform.ToTensor()와 비슷하다고 보면 됩니다.\n\n이어서 '검증 및 테스트 데이터용' 변환기입니다. 필수적인 변환기만 적용해 정의합니다.","metadata":{}},{"cell_type":"code","source":"transform_test = A.Compose([\n    A.Resize(450, 650),\n    A.Normalize(),\n    ToTensorV2()\n])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:47.120092Z","iopub.execute_input":"2023-10-03T10:20:47.120838Z","iopub.status.idle":"2023-10-03T10:20:47.136481Z","shell.execute_reply.started":"2023-10-03T10:20:47.120808Z","shell.execute_reply":"2023-10-03T10:20:47.135553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"크기는 당연히 훈련 데이터와 똑같에 맞추는 게 좋고, 픽셀 값 범위도 비슷해야(정규화해야) 서로 비교하기 쉽습니다. 마지막으로 파이토치는 텐서 객체만 취급하기 때문에 ToTensorV2() 변환기도 꼭 필요합니다.","metadata":{}},{"cell_type":"markdown","source":"### [4] Create datasets & a data loader (데이터셋 및 데이터 로더 생성)\n\n데이터 준비의 마지막 단계입니다. 데이터셋부터 정의해봅시다.","metadata":{}},{"cell_type":"code","source":"img_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n\ndataset_train = ImageDataset(train, img_dir = img_dir, transform = transform_train)\ndataset_valid = ImageDataset(valid, img_dir = img_dir, transform = transform_test)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:47.137855Z","iopub.execute_input":"2023-10-03T10:20:47.138414Z","iopub.status.idle":"2023-10-03T10:20:47.148814Z","shell.execute_reply.started":"2023-10-03T10:20:47.138341Z","shell.execute_reply":"2023-10-03T10:20:47.147953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"훈련 데이터셋(dataset_train)을 만들 때는 훈련용 변환기(transform_train)를, 검증 데이터셋(dataset_valid)을 만들 때는 검증/테스트용 변환기(transform_test)를 전달했습니다.\n\n이번는 멀티프로세싱을 활용해보겠습니다. 모델 훈련 시간이 꽤 걸리기 때문입니다. 멀티프로세싱을 사용하려면 다음과 같이 데이터 로더의 시드값을 고정해야 합니다. 먼저 seed_worker()를 정의하고 제너레이터를 생성합니다.","metadata":{}},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    \ng = torch.Generator()\ng.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:47.152105Z","iopub.execute_input":"2023-10-03T10:20:47.152589Z","iopub.status.idle":"2023-10-03T10:20:47.162149Z","shell.execute_reply.started":"2023-10-03T10:20:47.152559Z","shell.execute_reply":"2023-10-03T10:20:47.161248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"이어서 데이터 로더도 생성합니다. 훈련 데이터가 1,821개로 그렇게 많지 않아서 배치 크게는 4로 작게 설정했습니다.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader # 데이터 로더 생성을 위한 클래스\n\nbatch_size = 4\n\nloader_train = DataLoader(dataset_train, batch_size = batch_size,\n                         shuffle = True, worker_init_fn = seed_worker,\n                         generator = g, num_workers = 2)\nloader_valid = DataLoader(dataset_valid, batch_size = batch_size,\n                         shuffle = False, worker_init_fn = seed_worker,\n                         generator = g, num_workers = 2)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:47.163636Z","iopub.execute_input":"2023-10-03T10:20:47.164362Z","iopub.status.idle":"2023-10-03T10:20:47.173009Z","shell.execute_reply.started":"2023-10-03T10:20:47.164327Z","shell.execute_reply":"2023-10-03T10:20:47.172135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Create Model (모델 생성)\n\n이번에는 모델을 직접 설계하지 않고 사전 훈련된 모델을 전이 학습시키는 방식으로 만들어보겠습니다.","metadata":{}},{"cell_type":"markdown","source":"### [1] Pre-trained models and transfer learing (사전 훈련 모델과 전이 학습)\n\n사전 훈련 모델(pretrained model)이란 말 그대로 이미 한 분야에서 훈련을 마친 모델을 일컬으며, 전이 학습(transfer learing)이란 사전 훈련 모델을 유사한 다른 영역에서 재훈련시키는 기법입니다. 비유하자면, 분야 전문가(사전 훈련 모델)를 모셔와서 우리 회사만의 특수한 상황을 알려드린 후(전이 학습) 컨설팅받는 것과 비슷합니다.","metadata":{}},{"cell_type":"markdown","source":"### [2] Create an EfficientNet model (EfficientNet 모델 생성)\n\nEfficientNet은 2019년 5월에 개발된 CNN 모델로, 우수한 성능을 보여 주목을 받았습니다. 토론 내용에 따르면 본 경진대회에서는 EfficientNet이 우수한 성능을 보인다는 의견이 많았습니다. 'best single model'을 주제로 토론이 자주 벌어지니 미리 찾아보세요.\n\nLuke Melas-Kyriazi 라는 사람이 EfficientNet을 모듈로 구현해놨습니다. efficient_pytorch 모듈인데, 캐글 환경에서 설치되어 있지 않아서 별도로 설치해야 합니다. 다음 코드로 설치를 진행합니다.","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet-pytorch==0.7.1","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:47.174223Z","iopub.execute_input":"2023-10-03T10:20:47.175055Z","iopub.status.idle":"2023-10-03T10:20:58.143388Z","shell.execute_reply.started":"2023-10-03T10:20:47.175021Z","shell.execute_reply":"2023-10-03T10:20:58.141790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"efficientnet_pytorch 모듈의 EfficientNet 모델을 임포트하고 사전 훈련된 efficientnet-b7을 불러와서 device 장비에 할당합니다.","metadata":{}},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\n\nmodel = EfficientNet.from_pretrained('efficientnet-b7', num_classes = 4) # (1)\n\nmodel = model.to(device) # 장비_할당","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:20:58.145339Z","iopub.execute_input":"2023-10-03T10:20:58.145923Z","iopub.status.idle":"2023-10-03T10:21:06.952764Z","shell.execute_reply.started":"2023-10-03T10:20:58.145888Z","shell.execute_reply":"2023-10-03T10:21:06.951743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"(1)에서 efficient-b7을 불러올 때 전달한 num_classes 파라미터는 최종 출력값 개수를 뜻합니다. EfficientNet은 타깃값이 1,000개인 이미지 데이터로 사전 훈련한 모델이므로 num_classes에 아무 값도 전달하지 않으면 최종 출력값이 1,000개가 됩니다. 하지만 본 경진대회에서 예측해야 하는 타깃값은 총 4개이므로 4를 전달했습니다.","metadata":{}},{"cell_type":"markdown","source":"## 4. Train Model & Validate Performance (모델 훈련 및 성능 검증)\n\n손실 함수와 옵티마이저를 설정해 훈련시킨 후 성능을 확인해보겠습니다.","metadata":{}},{"cell_type":"markdown","source":"### [1] Set Loss Function & Optimizer (손실 함수와 옵티마이저 설정)\n\n손실 함수부터 CrossEntropyLoss()로 정의하겠습니다.","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:21:06.954066Z","iopub.execute_input":"2023-10-03T10:21:06.954718Z","iopub.status.idle":"2023-10-03T10:21:06.960417Z","shell.execute_reply.started":"2023-10-03T10:21:06.954676Z","shell.execute_reply":"2023-10-03T10:21:06.959048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"다음으로 옵티마이저를 정의합니다. 이번에는 AdamW 라는 옵티마이저를 사용해보겠습니다. AdamW는 Adam에 가중치 감쇠를 추가로 적용해서 일반화 성능이 더 우수합니다. 가중치 감쇠(weight decay)란 가중치를 작게 조절하는 규제 기법으로, 과대적합을 억제해줍니다.","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr = 0.00006, weight_decay = 0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:21:06.961749Z","iopub.execute_input":"2023-10-03T10:21:06.962368Z","iopub.status.idle":"2023-10-03T10:21:07.369534Z","shell.execute_reply.started":"2023-10-03T10:21:06.962338Z","shell.execute_reply":"2023-10-03T10:21:07.368565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"학습률은 0.00006으로 설정했습니다. 여러 학습률을 적용해 실험해보시기를 권장합니다. weight_decay는 가중치 감쇠를 의미하는 파라미터입니다. 여기서는 0.0001로 작은 값을 전달해서 미세하게 규제를 적용했습니다.","metadata":{}},{"cell_type":"markdown","source":"### [2] Train & Validate Performance (훈련 및 성능 검증)\n\n'매 에폭마다 검증'하는 방식으로 훈련을 진행하겠습니다. 더 오래 걸리지만, 과대적합 없이 훈련이 잘 되고 있는지 확인할 수 있다는 장점이 있습니다.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산 함수\nfrom tqdm.notebook import tqdm # 진행률 표시 막대\nepochs = 5\n\n# 총 에폭만큼 반복\nfor epoch in range(epochs):\n    # == [ 훈련 ] ==============================\n    model.train()         # 모델을 훈련 상태로 설정\n    epoch_train_loss = 0  # 에폭별 손실값 초기화 (훈련 데이터용)\n    \n    # '반복 횟수'만큼 반복\n    for images, labels in tqdm(loader_train): # (2)\n        # 이미지, 레이블(타깃값) 데이터 미니배치를 장비에 할당\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 옵티마이저 내 기울기 초기화\n        optimizer.zero_grad()\n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n        loss = criterion(outputs, labels)\n        # 현재 배치에서의 손실 수차 (훈련 데이터용)\n        epoch_train_loss += loss.item()\n        loss.backward()  # 역전파 수행\n        optimizer.step() # 가중치 갱신\n    # 훈련 데이터 손실값 출력\n    print(f'에폭 [{epoch+1}/{epochs}] - 훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n    \n    # == [ 검증 ] ==============================\n    model.eval()          # 모델을 평가 상태로 설정\n    epoch_valid_loss = 0  # 에폭별 손실값 초기화 (검증 데이터용)\n    preds_list = []       # 예측 확률값 저장용 리스트 초기화\n    true_onehot_list = [] # 실제 타깃값 저장용 리스트 초기화\n    \n    with torch.no_grad(): # 기울기 계산 비활성화\n        # 미니배치 단위로 검증\n        for images, labels in loader_valid:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            epoch_valid_loss += loss.item()\n            \n            # 예측 확률값\n            preds = torch.softmax(outputs.cpu(), dim=1).numpy()\n            # (5) 실젯값 (원-핫 인코딩 형식)\n            true_onehot = torch.eye(4, device = device)[labels].cpu().numpy()\n            # (6) 예측 확률값과 실젯값 저장\n            preds_list.extend(preds)\n            true_onehot_list.extend(true_onehot)\n    # 검증 데이터 손실값 및 ROC AUC 점수 출력\n    print(f'에폭 [{epoch+1}/{epochs}] - 검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f} / 검증 데이터 ROC AUC : {roc_auc_score(true_onehot_list, preds_list):.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:21:07.371175Z","iopub.execute_input":"2023-10-03T10:21:07.371871Z","iopub.status.idle":"2023-10-03T10:47:56.532687Z","shell.execute_reply.started":"2023-10-03T10:21:07.371838Z","shell.execute_reply":"2023-10-03T10:47:56.531579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Predict & Submission (예측 및 제출)\n\n훈련이 끝났으니, 이제 예측을 해야겠죠? 테스트용 데이터셋과 데이터 로더를 생성합니다.","metadata":{}},{"cell_type":"code","source":"dataset_test = ImageDataset(test, img_dir = img_dir,\n                           transform = transform_test, is_test = True)\n\nloader_test = DataLoader(dataset_test, batch_size = batch_size,\n                         shuffle = False, worker_init_fn = seed_worker,\n                        generator = g, num_workers = 2)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:52:28.605789Z","iopub.execute_input":"2023-10-03T10:52:28.606128Z","iopub.status.idle":"2023-10-03T10:52:28.611017Z","shell.execute_reply.started":"2023-10-03T10:52:28.606100Z","shell.execute_reply":"2023-10-03T10:52:28.610122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### [1] Predict (예측)\n\n테스트 데이터를 활용해 타깃 확률을 예측해봅니다.","metadata":{}},{"cell_type":"code","source":"model.eval() # 모델을 평가 상태로 설정\n\npreds = np.zeros((len(test), 4)) # (1) 예측값 저장용 배열 초기화\n\nwith torch.no_grad():\n    for i, images in enumerate(loader_test):\n        images = images.to(device)\n        outputs = model(images)\n        # 타깃 예측 확률\n        preds_part = torch.softmax(outputs.cpu(), dim = 1).squeeze().numpy() # (2)\n        preds[i * batch_size:(i + 1) * batch_size] += preds_part # (3)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:52:31.298861Z","iopub.execute_input":"2023-10-03T10:52:31.299237Z","iopub.status.idle":"2023-10-03T10:54:04.913692Z","shell.execute_reply.started":"2023-10-03T10:52:31.299187Z","shell.execute_reply":"2023-10-03T10:54:04.912453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"(1) 먼저 예측값을 저장하기 위해 배열을 준비합니다. np.zeros()는 전달받은 형상 크기에 맞게 0으로 채워진 배열을 반환합니다. 인수로 전달한 len(test)와 4는 각각 행과 열의 개수입니다. 타깃값이 4개라서 열이 4개입니다.\n\n(2)와 (3)에서는 타깃 예측 확률을 구합니다. (2) outputs에는 신경망 출력값이 배치 크기만큼 존재합니다. 그 출력값에 소프트맥스 함수를 취해 확률값을 구해 preds_part에 할당했습니다. (3)이 preds_part를 이용해 preds 배열을 갱신합니다. preds 배열에서 해당하는 행 위치에 있는 0을 배치 크기만큼 확률값들로 갱신한 것입니다.\n\nfor문이 끝나면 다음 그림과 같이 preds에 모든 테스트 데이터의 예측 확률값들이 저장돼 있을 것입니다.","metadata":{}},{"cell_type":"markdown","source":"### [2] Submission (제출)\n\n마지막으로 제출 파일을 만들고 제출해보겠습니다.","metadata":{}},{"cell_type":"code","source":"submission[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds\nsubmission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T10:54:14.461099Z","iopub.execute_input":"2023-10-03T10:54:14.461540Z","iopub.status.idle":"2023-10-03T10:54:14.491615Z","shell.execute_reply.started":"2023-10-03T10:54:14.461508Z","shell.execute_reply":"2023-10-03T10:54:14.490781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The End.","metadata":{}}]}