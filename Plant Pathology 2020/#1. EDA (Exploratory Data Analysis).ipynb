{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## EDA (Exploratory Data Analysis) for beginner\n\nIt doesn't look like there's much to analyze, so let's take a quick look at the CSV data, see the distribution of the target values, and then output the actual image.\n\n분석할 요소가 많지 않은 것 같습니다. csv 데이터를 간단히 둘러보고, 타깃값 분포를 알아본 뒤 실제 이미지를 출력해보겠습니다.\n\n### 1. Load the data (데이터 불러오기)\n\nFor a quick tour of the CSV data, we'll start by importing the CSV file.\n\ncsv 데이터를 간단히 둘러보기 위해 우선 csv 파일을 불러옵니다.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')\n\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:26:29.444822Z","iopub.execute_input":"2023-10-03T04:26:29.445206Z","iopub.status.idle":"2023-10-03T04:26:29.472636Z","shell.execute_reply.started":"2023-10-03T04:26:29.445174Z","shell.execute_reply":"2023-10-03T04:26:29.471019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both the training and test data have the same number of columns, 1,821. The training data has four more columns than the test data because it has four target values.\n\nNext, let's output the first five rows of the training data.\n\n훈련 데이터와 테스트 데이터 모두 1,821개로 개수가 같네요. 타깃값이 4개라서 훈련 데이터의 열 개수가 테스트 데이터보다 4개 더 많습니다.\n\n다음으로 훈련 데이터의 첫 다섯행을 출력해봅시다.","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:30:02.044540Z","iopub.execute_input":"2023-10-03T04:30:02.044917Z","iopub.status.idle":"2023-10-03T04:30:02.056353Z","shell.execute_reply.started":"2023-10-03T04:30:02.044886Z","shell.execute_reply":"2023-10-03T04:30:02.054867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"image_id represents the filename of the training image data. This means that the image files for training are named Train_0.jpg, Train_1.jpg, Train_2.jpg, and so on (the image filenames are located in the images directory).\n\nThe healthy, multiple_diseases, rust, and scap columns are the target values. They are written in a one-hot encoding format.\n\nimage_id는 훈련 이미지 데이터의 파일명을 나타냅니다. 훈련용 이미지 파일의 이름이 Train_0.jpg, Train_1.jpg, Train_2.jpg 식이라는 뜻입니다(이미지 파일명은 images 디렉터리에 있습니다).\n\nhealthy, multiple_diseases, rust, scap 열은 타깃값입니다. 원-핫 인코딩 형식으로 기록되어 있습니다.","metadata":{}},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:29:39.534912Z","iopub.execute_input":"2023-10-03T04:29:39.535261Z","iopub.status.idle":"2023-10-03T04:29:39.544928Z","shell.execute_reply.started":"2023-10-03T04:29:39.535233Z","shell.execute_reply":"2023-10-03T04:29:39.543538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no target values in the test data, so there are only image_ids. There are also 1,821 test data, so the image data filenames would be Test_0.jpg through Test_1820.jpg.\n\n테스트 데이터에는 타깃값이 없으니 image_id만 있습니다. 테스트 데이터도 총 1,821개이므로 이미지 데이터 파일명은 Test_0.jpg부터 Test_1820.jpg까지 있겠네요.","metadata":{}},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:30:53.930655Z","iopub.execute_input":"2023-10-03T04:30:53.931043Z","iopub.status.idle":"2023-10-03T04:30:53.945481Z","shell.execute_reply.started":"2023-10-03T04:30:53.931013Z","shell.execute_reply":"2023-10-03T04:30:53.944368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"타깃값 4개의 값이 모두 0.25입니다. 각 확률을 25%로 일괄 기재해둔 것이죠","metadata":{}},{"cell_type":"markdown","source":"## 2. Data Visualization (데이터 시각화)\n\nWe're going to visualize the data in the CSV file we just looked at.\n\n방금 살펴본 csv 파일의 데이터를 시각화해볼 겁니다.\n\n### [1] Distribution of target value (타깃값 분포)\n\nThe first thing we'll do is divide the data by target value to see how many data points correspond to each target value.\n\nWe've assigned each of the variables 'healthy', 'multiple_diseases', 'rust', and 'scab' with data from the target value. Let's plot a pie graph of the target value distribution using these variables.\n\n가장 먼저 데이터를 타깃값별로 나눠보겠습니다. 각 타깃값에 해당하는 데이터가 몇 개씩인지 알아보기 위해서입니다.\n\n'healthy', 'multiple_diseases', 'rust', 'scab' 각 변수에 타깃값의 데이터를 할당했습니다. 이 변수들을 사용해 타깃값 분포를 파이 그래프로 그려보겠습니다.","metadata":{}},{"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nmpl.rc('font', size = 15)\nplt.figure(figsize = (7, 7))\n\nhealthy = train.loc[train['healthy'] == 1]\nmultiple_diseases = train.loc[train['multiple_diseases'] == 1]\nrust = train.loc[train['rust'] == 1]\nscab = train.loc[train['scab'] == 1]\n\nlabel = ['healthy', 'multiple_diseases', 'rust', 'scab']\n\nplt.pie([len(healthy), len(multiple_diseases), len(rust), len(scab)],\n         labels = label, autopct = '%.1f%%')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:36:25.236195Z","iopub.execute_input":"2023-10-03T04:36:25.236584Z","iopub.status.idle":"2023-10-03T04:36:25.471929Z","shell.execute_reply.started":"2023-10-03T04:36:25.236555Z","shell.execute_reply":"2023-10-03T04:36:25.470393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The ratio is rust > scab > healthy > multiple_diseases. There are relatively few multiple_diseases compared to the rest of the targets. Because of the large difference in proportions, it would be better to divide the training and validation data according to the proportions of the target values.\n\n비율이 rust > scab > healthy > multiple_diseases 순입니다. 나머지 타깃값에 비해 multiple_disease가 상대적으로 적습니다. 비율 차이가 크기 때문에 훈련 데이터와 검증 데이터로 나눌 때 타깃값 비율에 맞게 나누는 게 좋겠네요.","metadata":{}},{"cell_type":"markdown","source":"### [2] Image Output (이미지 출력)\n\nTo display an image for each target value, we'll first define a show_image() function that takes an image ID and displays the image on the screen, find the image ID for each target value to pass to the function, and write code to get the image_id of the last 6 image data for each target value.\n\nOnce we have the image IDs, let's use the show_image() function to output the leaf image.\n\n각 타깃값에 해당하는 이미지를 출력해보겠습니다. 이미지 ID를 전달받아 화면에 이미지를 출력하는 show_image() 함수를 먼저 정의하고 이 함수에 전달할 타깃값별 이미지 ID를 구해보겠습니다. 그리고 타깃값별로 마지막 6개 이미지 데이터의 image_id를 구하는 코드를 작성ㅇ합니다.\n\n이미지 ID를 알아내면, 이제 show_image() 함수로 잎사귀 이미지를 출력해봅시다.","metadata":{}},{"cell_type":"code","source":"import matplotlib.gridspec as gridspec\nimport cv2\n\ndef show_image(img_ids, rows = 2, cols = 3):\n    assert len(img_ids) <= rows * cols # 이미지가 행/열 개수보다 많으면 오류 발생\n    \n    plt.figure(figsize = (15, 8))\n    grid = gridspec.GridSpec(rows, cols)\n    \n    for idx, img_id in enumerate(img_ids):\n        img_path = f'{data_path}/images/{img_id}.jpg'\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        ax = plt.subplot(grid[idx])\n        ax.imshow(image)\n\nnum_of_imgs = 6\nlast_healthy_img_ids = healthy['image_id'][-num_of_imgs:]\nlast_multiple_diseases_img_ids = multiple_diseases['image_id'][-num_of_imgs:]\nlast_rust_img_ids = rust['image_id'][-num_of_imgs:]\nlast_scab_img_ids = scab['image_id'][-num_of_imgs:]\n\nshow_image(last_healthy_img_ids)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:48:31.545051Z","iopub.execute_input":"2023-10-03T04:48:31.545388Z","iopub.status.idle":"2023-10-03T04:48:35.976330Z","shell.execute_reply.started":"2023-10-03T04:48:31.545362Z","shell.execute_reply":"2023-10-03T04:48:35.974612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is a healthy leaf, and it's overall clean.\n\nNext, let's print out a leaf with multiple diseases, a leaf with rust disease, and a leaf with red mold disease.\n\n건강한 잎사귀답게 전반적으로 깨끗하네요.\n\n다음으로 여러 질병에 걸린 잎사귀, 녹병에 걸린 잎사귀와 붉은곰팡이병에 걸린 잎사귀를 출력해봅시다.","metadata":{}},{"cell_type":"code","source":"show_image(last_multiple_diseases_img_ids)\nshow_image(last_rust_img_ids)\nshow_image(last_scab_img_ids)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:51:23.225542Z","iopub.execute_input":"2023-10-03T04:51:23.225908Z","iopub.status.idle":"2023-10-03T04:51:36.510848Z","shell.execute_reply.started":"2023-10-03T04:51:23.225878Z","shell.execute_reply":"2023-10-03T04:51:36.509688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Analysis Summary & Modeling Strategy\n\n### Analysis Summary (분석 정리)\n\n1. The identity feature of the CSV file is the image filename. We just need to add the pathname and extension of the file to get the location of the file.\n2. In the training data, we recorded the leaf states (target values) in the form of one-hot encoding divided into four columns.\n3. Since the ratio difference between the target values is large, we need to divide the training data and the validation data according to the ratio of the target values.\n\n1. csv 파일의 id 피처는 이미지 파일명입니다. 파일의 경로명과 확장명만 추가하면 파일의 위치를 바로 얻어올 수 있습니다.\n2. 훈련 데이터에는 잎사귀 상태(타깃값)를 4개 열로 나눠 원-핫 인코딩 형태로 기록해뒀습니다.\n3. 타깃값들의 비율 차이가 커서 훈련 데이터와 검증 데이터를 나눌 때 타깃값 비율에 맞게 나눠야 합니다.\n\n### Modeling Strategy (모델링 전략)\n\nInstead of designing our own deep learning model, we'll use a pre-trained model known to perform well to perform transfer learning. We'll focus on learning useful performance improvement techniques outside of neural network design.\n\n- Baseline model\n  - Data augmentation: applying various transformers\n  - Neural Network Structure: Pre-trained model (efficientnet-b7)\n  - Optimizer: AdamW\n\n- Performance Improvements\n  - Data augmentation: Same as baseline\n  - Neural network structure: same as baseline\n  - Optimizer: Same as baseline\n  - Training phase optimizations: Scheduler settings, increased epochs\n  - Prediction phase optimizations: Test phase data augmentation (TTA), label smoothing\n\n딥러닝 모델을 직접 설계하지 않고, 성능이 우수하다고 알려진 사전 훈련 모델을 활용해 전이 학습을 수행하겠습니다. 신경망 설계 외의 유용한 성능 향상 기법들을 배우는 데 집중하려고 합니다.\n\n- 베이스라인 모델\n  - 데이터 증강 : 다양한 변환기 적용\n  - 신경망 구조 : 사전 훈련 모델(efficientnet-b7)\n  - 옵티마이저 : AdamW\n\n\n- 성능 개선\n  - 데이터 증강 : 베이스라인과 동일\n  - 신경망 구조 : 베이스라인과 동일\n  - 옵티마이저 : 베이스라인과 동일\n  - 훈련 단계 최적화 : 스케줄러 설정, 에폭 증가\n  - 예측 단계 최적화 : 테스트 단계 데이터 증강(TTA), 레이블 스무딩","metadata":{}},{"cell_type":"markdown","source":"The End.","metadata":{}}]}